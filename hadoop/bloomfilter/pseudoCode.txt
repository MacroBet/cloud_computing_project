
JOB 1 

class Mapper

    method Map(doc d)
        for all movies_id in doc
            key = get(rating)
            Emit(key, one)

class Reducer

    method Reduce(Key rating, counts[movId1, movId2, .....])
        sum <- 0
        for all elem in counts 
            sum <- sum + elem

        get_k(sum);
        get_m(sum);
        res = concatenate(k ,m)

        Emit(key, res)



JOB 2

class Mapper
                                key       0  1
    HashMap<> parameters      //ratings->[m][k]
    
    method SetUp(context)
       
        rf = readFromFile("hdfs://hadoop-namenode:9820/user/hadoop/output/part-r-00000")

        foreach line in rf
            value = get(line[rating])
            m = get(line[m])
            k = get(line[k])
            parameters.add(value, (m,k))



    method Map(Doc doc)

        foreach term t in doc

            rating = t.rating
            movies_id = t.movies_id
            bloomFilter(movies_id, parameters.get(rating)[0], parameters.get(rating)[1])
            Emit(rating, bloomFilter)    //rating, 00110111

    
class Reducer

    method Reduce(key rating, bloomFilter[b1, b2....])

        tempBloom(null, parameters.get(rating)[0], parameters.get(rating)[1])   //000000000

        foreach elm in bloomFilter

            tempBloom = tempBloom || elm
        
        Emit(rating, tempBloom)